# This is a config file that typescriptifies the packages under the example folder.
# and some other packages.

packages:
  - path: 'test/TensorBase.h'
    bindings_out_path: 'test/out'
    header_out_path: 'test/out'
    indent: "\t"
    type_mappings:
      Shape:
        ts: 'number[]'
      Dim:
        ts: 'number'
      dtype:
        ts: 'number'
        napi: 'Number'
        casts_to: 'fl::dtype'
        cast_napi: 'Int32Value'
    ignored_methods:
      - 'scalar'
      - 'pad'
      - 'argsort'
      - 'fromScalar'
      # TODO: following op should not be ignored (ignored for compilation errors)
    header_frontmatter: |
      #include "flashlight/fl/autograd/Functions.h"
      #include "flashlight/fl/autograd/tensor/AutogradExtension.h"
      #include "flashlight/fl/autograd/tensor/AutogradOps.h"
      #include "flashlight/fl/common/DynamicBenchmark.h"
      #include "flashlight/fl/nn/Init.h"
      #include "flashlight/fl/runtime/Device.h"
      #include "flashlight/fl/runtime/Stream.h"
      #include "flashlight/fl/tensor/Compute.h"
      #include "flashlight/fl/tensor/Index.h"
      #include "flashlight/fl/tensor/Init.h"
      #include "flashlight/fl/tensor/Random.h"
      #include "flashlight/fl/tensor/TensorAdapter.h"
    bindings_frontmatter: |
      #include <atomic>
      #include <iostream>
      #include <string>
    global_vars: |
      static std::atomic<size_t> g_bytes_used = 0;
      static std::atomic<bool> g_row_major = true;
    global_type_out_transforms:
      Tensor: |
        g_bytes_used += /return/.bytes();
    method_arg_check_transforms:
      arange: |
        if (!info[0].IsNumber()) {
          Napi::TypeError::New(info.Env(), "`arange` expects args[0] to be typeof `number`").ThrowAsJavaScriptException();
          return env.Null();
        }
        if (!info[1].IsNumber()) {
          Napi::TypeError::New(info.Env(),"`arange` expects args[1] to be typeof `number`").ThrowAsJavaScriptException();
          return env.Null();
        }
        if (!info[2].IsNumber()) {
          Napi::TypeError::New(info.Env(), "`arange` expects args[2] to be typeof `number`").ThrowAsJavaScriptException();
          return env.Null();
        }
    method_return_transforms:
      any: |
        /return/ = fl::any(/arg_0/, /arg_1/, /arg_2/);
        auto axes_set = std::unordered_set<int>(/arg_1/.begin(), /arg_1/.end());
        auto base_shape = (/arg_0/).shape().get();
        std::vector<fl::Dim> new_shape;
        for (size_t idx = 0; idx < base_shape.size(); ++idx) {
          if (axes_set.count(idx) || (axes_set.size() == 0)) {
            if (/arg_2/) {
              new_shape.emplace_back(1);
            }
            continue;
          }
          new_shape.emplace_back(base_shape[idx]);
        }
        const auto& shape = fl::Shape(new_shape);
        /return/ = fl::reshape(/return/, shape);
      all: |
        /return/ = fl::all(/arg_0/, /arg_1/, /arg_2/);
        auto axes_set = std::unordered_set<int>(/arg_1/.begin(), /arg_1/.end());
        auto base_shape = (/arg_0/).shape().get();
        std::vector<fl::Dim> new_shape;
        for (size_t idx = 0; idx < base_shape.size(); ++idx) {
          if (axes_set.count(idx) || (axes_set.size() == 0)) {
            if (/arg_2/) {
              new_shape.emplace_back(1);
            }
            continue;
          }
          new_shape.emplace_back(base_shape[idx]);
        }
        const auto& shape = fl::Shape(new_shape);
        /return/ = fl::reshape(/return/, shape);
      amin: |
        /return/ = fl::amin(/arg_0/, /arg_1/, /arg_2/);
        auto axes_set = std::unordered_set<int>(/arg_1/.begin(), /arg_1/.end());
        auto base_shape = (/arg_0/).shape().get();
        std::vector<fl::Dim> new_shape;
        for (size_t idx = 0; idx < base_shape.size(); ++idx) {
          if (axes_set.count(idx) || (axes_set.size() == 0)) {
            if (/arg_2/) {
              new_shape.emplace_back(1);
            }
            continue;
          }
          new_shape.emplace_back(base_shape[idx]);
        }
        const auto& shape = fl::Shape(new_shape);
        /return/ = fl::reshape(/return/, shape);
      amax: |
        /return/ = fl::amax(/arg_0/, /arg_1/, /arg_2/);
        auto axes_set = std::unordered_set<int>(/arg_1/.begin(), /arg_1/.end());
        auto base_shape = (/arg_0/).shape().get();
        std::vector<fl::Dim> new_shape;
        for (size_t idx = 0; idx < base_shape.size(); ++idx) {
          if (axes_set.count(idx) || (axes_set.size() == 0)) {
            if (/arg_2/) {
              new_shape.emplace_back(1);
            }
            continue;
          }
          new_shape.emplace_back(base_shape[idx]);
        }
        const auto& shape = fl::Shape(new_shape);
        /return/ = fl::reshape(/return/, shape);
      argmin: |
        /return/ = fl::argmin(/arg_0/, /arg_1/, /arg_2/);
        auto axes_set = std::unordered_set<int>{static_cast<int>(/arg_1/)};
        auto base_shape = (/arg_0/).shape().get();
        std::vector<fl::Dim> new_shape;
        for (size_t idx = 0; idx < base_shape.size(); ++idx) {
          if (axes_set.count(idx) || (axes_set.size() == 0)) {
            if (/arg_2/) {
              new_shape.emplace_back(1);
            }
            continue;
          }
          new_shape.emplace_back(base_shape[idx]);
        }
        const auto& shape = fl::Shape(new_shape);
        /return/ = fl::reshape(/return/, shape);
      argmax: |
        /return/ = fl::argmax(/arg_0/, /arg_1/, /arg_2/);
        auto axes_set = std::unordered_set<int>{static_cast<int>(/arg_1/)};
        auto base_shape = (/arg_0/).shape().get();
        std::vector<fl::Dim> new_shape;
        for (size_t idx = 0; idx < base_shape.size(); ++idx) {
          if (axes_set.count(idx) || (axes_set.size() == 0)) {
            if (/arg_2/) {
              new_shape.emplace_back(1);
            }
            continue;
          }
          new_shape.emplace_back(base_shape[idx]);
        }
        const auto& shape = fl::Shape(new_shape);
        /return/ = fl::reshape(/return/, shape);
      countNonzero: |
        /return/ = fl::countNonzero(/arg_0/, /arg_1/, /arg_2/);
        auto axes_set = std::unordered_set<int>(/arg_1/.begin(), /arg_1/.end());
        auto base_shape = (/arg_0/).shape().get();
        std::vector<fl::Dim> new_shape;
        for (size_t idx = 0; idx < base_shape.size(); ++idx) {
          if (axes_set.count(idx) || (axes_set.size() == 0)) {
            if (/arg_2/) {
              new_shape.emplace_back(1);
            }
            continue;
          }
          new_shape.emplace_back(base_shape[idx]);
        }
        const auto& shape = fl::Shape(new_shape);
        /return/ = fl::reshape(/return/, shape);
      sum: |
        /return/ = fl::sum(/arg_0/, /arg_1/, /arg_2/);
        auto axes_set = std::unordered_set<int>(/arg_1/.begin(), /arg_1/.end());
        auto base_shape = (/arg_0/).shape().get();
        std::vector<fl::Dim> new_shape;
        for (size_t idx = 0; idx < base_shape.size(); ++idx) {
          if (axes_set.count(idx) || (axes_set.size() == 0)) {
            if (/arg_2/) {
              new_shape.emplace_back(1);
            }
            continue;
          }
          new_shape.emplace_back(base_shape[idx]);
        }
        const auto& shape = fl::Shape(new_shape);
        /return/ = fl::reshape(/return/, shape);
      mean: |
        /return/ = fl::mean(/arg_0/, /arg_1/, /arg_2/);
        auto axes_set = std::unordered_set<int>(/arg_1/.begin(), /arg_1/.end());
        auto base_shape = (/arg_0/).shape().get();
        std::vector<fl::Dim> new_shape;
        for (size_t idx = 0; idx < base_shape.size(); ++idx) {
          if (axes_set.count(idx) || (axes_set.size() == 0)) {
            if (/arg_2/) {
              new_shape.emplace_back(1);
            }
            continue;
          }
          new_shape.emplace_back(base_shape[idx]);
        }
        const auto& shape = fl::Shape(new_shape);
        /return/ = fl::reshape(/return/, shape);
      median: |
        /return/ = fl::median(/arg_0/, /arg_1/, /arg_2/);
        auto axes_set = std::unordered_set<int>(/arg_1/.begin(), /arg_1/.end());
        auto base_shape = (/arg_0/).shape().get();
        std::vector<fl::Dim> new_shape;
        for (size_t idx = 0; idx < base_shape.size(); ++idx) {
          if (axes_set.count(idx) || (axes_set.size() == 0)) {
            if (/arg_2/) {
              new_shape.emplace_back(1);
            }
            continue;
          }
          new_shape.emplace_back(base_shape[idx]);
        }
        const auto& shape = fl::Shape(new_shape);
        /return/ = fl::reshape(/return/, shape);
      var: |
        /return/ = fl::var(/arg_0/, /arg_1/, /arg_2/, /arg_3/);
        auto axes_set = std::unordered_set<int>(/arg_1/.begin(), /arg_1/.end());
        auto base_shape = (/arg_0/).shape().get();
        std::vector<fl::Dim> new_shape;
        for (size_t idx = 0; idx < base_shape.size(); ++idx) {
          if (axes_set.count(idx) || (axes_set.size() == 0)) {
            if (/arg_3/) {
              new_shape.emplace_back(1);
            }
            continue;
          }
          new_shape.emplace_back(base_shape[idx]);
        }
        const auto& shape = fl::Shape(new_shape);
        /return/ = fl::reshape(/return/, shape);
      std: |
        /return/ = fl::median(/arg_0/, /arg_1/, /arg_2/);
        auto axes_set = std::unordered_set<int>(/arg_1/.begin(), /arg_1/.end());
        auto base_shape = (/arg_0/).shape().get();
        std::vector<fl::Dim> new_shape;
        for (size_t idx = 0; idx < base_shape.size(); ++idx) {
          if (axes_set.count(idx) || (axes_set.size() == 0)) {
            if (/arg_2/) {
              new_shape.emplace_back(1);
            }
            continue;
          }
          new_shape.emplace_back(base_shape[idx]);
        }
        const auto& shape = fl::Shape(new_shape);
        /return/ = fl::reshape(/return/, shape);
      norm: |
        /return/ = fl::norm(/arg_0/, /arg_1/, /arg_2/, /arg_3/);
        if (p == std::numeric_limits<double>::infinity()) {
          /return/ = fl::abs(/arg_0/);
          /return/ = fl::amax(/arg_0/, /arg_1/, /arg_3/);
        }
        auto axes_set = std::unordered_set<int>(/arg_1/.begin(), /arg_1/.end());
        auto base_shape = (/arg_0/).shape().get();
        std::vector<fl::Dim> new_shape;
        for (size_t idx = 0; idx < base_shape.size(); ++idx) {
          if (axes_set.count(idx) || (axes_set.size() == 0)) {
            if (/arg_3/) {
              new_shape.emplace_back(1);
            }
            continue;
          }
          new_shape.emplace_back(base_shape[idx]);
        }
        const auto& shape = fl::Shape(new_shape);
        /return/ = fl::reshape(/return/, shape);
      arange: |
        /return/ = fl::arange(/arg_0/, /arg_1/, /arg_2/);
      full: |
        /return/ = fl::full(fl::Shape(/arg_0/), /arg_1/);
      identity: |
        /return/ = fl::identity(/arg_0/);
      iota: |
        /return/ = fl::iota(fl::Shape(/arg_0/), fl::Shape(/arg_1/));
      tril: |
        if (g_row_major) {
          /return/ = fl::triu(/arg_0/);
        } else {
          /return/ = fl::tril(/arg_0/);
        }
      triu: |
        if (g_row_major) {
          /return/ = fl::tril(/arg_0/);
        } else {
          /return/ = fl::triu(/arg_0/);
        }
      sort: |
        /return/ = fl::sort(/arg_0/, /arg_1/);
      matmul: |
        if (g_row_major) {
          /return/ = fl::matmul(/arg_1/, /arg_0/);
        } else {
          /return/ = fl::matmul(/arg_0/, /arg_1/);
        }
    method_arg_transforms:
      argmin:
        axis: |
          auto axis = axisArg(/arg/.As<Napi::Number>().Uint32Value(), g_row_major, /arg_0/->_tensor->ndim());
      argmax:
        axis: |
          auto axis = axisArg(/arg/.As<Napi::Number>().Uint32Value(), g_row_major, /arg_0/->_tensor->ndim());
      arange:
        start: |
          float start = /arg/.As<Napi::Number>().FloatValue();
        end: |
          float end = /arg/.As<Napi::Number>().FloatValue();
        step: |
          float step = /arg/.As<Napi::Number>().FloatValue();
      full:
        dims: |
          std::vector<long long> dims = jsArrayArg<long long>(/arg/.As<Napi::Array>(), g_row_major, false, env);
        val: |
          float val = /arg/.As<Napi::Number>().FloatValue();
      identity:
        dim: |
          int64_t dim = /arg/.As<Napi::Number>().Int64Value();
      iota:
        dims: |
          auto dims = jsArrayArg<long long>(/arg/.As<Napi::Array>(), g_row_major, false, env);
        tileDims: |
          auto tileDims = jsArrayArg<long long>(/arg/.As<Napi::Array>(), g_row_major, false, env);
      concatenate:
        axis: |
          auto axis = axisArg(/arg/.As<Napi::Number>().Int32Value(), g_row_major, (&tensors[0])->ndim());
        tensors: |
          auto tensors = jsTensorArrayArg<fl::Tensor>(/arg/.As<Napi::Array>(), env);
      sort:
        axis: |
          auto axis = /arg/.As<Napi::Number>().Uint32Value();
      tile:
        shape: |
          auto shape = jsArrayArg<long long>(/arg/.As<Napi::Array>(), g_row_major, false, env);
      transpose:
        axes: |
          auto axes = jsArrayArg<long long>(/arg/.As<Napi::Array>(), g_row_major, /arg_0/->_tensor->ndim(), env);
      reshape:
        shape: |
          auto shape = jsArrayArg<long long>(/arg/.As<Napi::Array>(), g_row_major, false, env);
    helper_funcs:
      arrayArg: |
        template <typename T>
        std::vector<T> arrayArg(const void* ptr, int len, bool reverse, int invert) {
          std::vector<T> out;
          out.reserve(len);
          for (auto i = 0; i < len; ++i) {
            const auto idx = reverse ? len - i - 1 : i;
            auto v = reinterpret_cast<const int64_t*>(ptr)[idx];
            if (invert && v < 0) {
              v = -v - 1;
            } else if (invert) {
              v = invert - v - 1;
            }
            out.emplace_back(v);
          }
          return out;
        }
      jsArrayArg: |
        template <typename T>
        std::vector<T> jsArrayArg(Napi::Array arr, bool reverse, int invert, Napi::Env env) {
          std::vector<T> out;
          const size_t len = static_cast<size_t>(arr.Length());
          out.reserve(len);
          for (size_t i = 0; i < len; ++i) {
            const auto idx = reverse ? len - i - 1 : i;
            Napi::Value val = arr[idx];
            if (!val.IsNumber()) {
              Napi::TypeError::New(env, "jsArrayArg requires `number[]`")
                  .ThrowAsJavaScriptException();
              return out;
            } else {
              int64_t v = val.As<Napi::Number>().Int64Value();
              if (invert && v < 0) {
                v = -v - 1;
              } else if (invert) {
                v = invert - v - 1;
              }
              out.emplace_back(v);
            }
          }
          return out;
        }
      jsTensorArrayArg: |
        template <typename T>
        std::vector<T> jsTensorArrayArg(Napi::Array arr, Napi::Env env) {
          std::vector<T> out;
          const size_t len = static_cast<size_t>(arr.Length());
          out.reserve(len);
          for (size_t i = 0; i < len; ++i) {
            Napi::Value temp = arr[i];
            if (temp.IsObject()) {
              Napi::Object tensor_obj = temp.As<Napi::Object>();
              if (tensor_obj.InstanceOf(Tensor::constructor->Value())) {
                Tensor* tensor = Napi::ObjectWrap<Tensor>::Unwrap(tensor_obj);
                out.emplace_back(*(tensor->_tensor));
              } else {
                Napi::TypeError::New(env, "jsTensorArrayArg requires `Tensor[]`")
                    .ThrowAsJavaScriptException();
                return out;
              }
            } else {
              Napi::TypeError::New(env, "jsTensorArrayArg requires `Tensor[]`")
                  .ThrowAsJavaScriptException();
              return out;
            }
          }
          return out;
        }
      axisArg: |
        uint32_t axisArg(int32_t axis, bool reverse, int ndim) {
          if (!reverse) {
            return static_cast<uint32_t>(axis);
          }
          if (axis >= 0) {
            return static_cast<uint32_t>(ndim - axis - 1);
          } else {
            return static_cast<uint32_t>(-axis - 1);
          }
        }
      ptrArrayArg: |
        template <typename T>
        std::vector<T> ptrArrayArg(const void* ptr, int len) {
          std::vector<T> out;
          out.reserve(len);
          for (auto i = 0; i < len; ++i) {
            auto ptrAsInt = reinterpret_cast<const int64_t*>(ptr)[i];
            auto ptr = reinterpret_cast<T*>(ptrAsInt);
            out.emplace_back(*ptr);
          }
          return out;
        }
      load: |
        fl::Tensor* load(std::string filename, Napi::Env env) {
          try {
            fl::Tensor tensor;
            fl::load(filename, tensor);
            auto* t = new fl::Tensor(tensor);
            g_bytes_used += t->bytes();
            return t;
          } catch (std::exception const& e) {
            Napi::TypeError::New(env, e.what()).ThrowAsJavaScriptException();
          }
        }
    global_methods:
      - name: '_init'
        is_void: true
        body: |
          static void _init(const Napi::CallbackInfo& info) {
            fl::init();
          }
      - name: '_bytesUsed'
        body: |
          static Napi::Value _bytesUsed(const Napi::CallbackInfo& info) {
            return Napi::Number::New(info.Env(), g_bytes_used);
          }
      - name: '_setRowMajor'
        is_void: true
        body: |
          static void _setRowMajor(const Napi::CallbackInfo& info) {
            g_row_major = true;
          }
      - name: '_setColMajor'
        is_void: true
        body: |
          static void _setColMajor(const Napi::CallbackInfo& info) {
            g_row_major = true;
          }
      - name: '_isRowMajor'
        body: |
          static Napi::Value _isRowMajor(const Napi::CallbackInfo& info) {
            return Napi::Boolean::New(info.Env(), g_row_major);
          }
      - name: '_isColMajor'
        body: |
          static Napi::Value _isColMajor(const Napi::CallbackInfo& info) {
            return Napi::Boolean::New(info.Env(), !g_row_major);
          }
      - name: '_dtypeFloat32'
        body: |
          static Napi::Value _dtypeFloat32(const Napi::CallbackInfo& info) {
            return Napi::Number::New(info.Env(), static_cast<double>(fl::dtype::f32));
          }
      - name: '_dtypeFloat64'
        body: |
          static Napi::Value _dtypeFloat64(const Napi::CallbackInfo& info) {
            return Napi::Number::New(info.Env(), static_cast<double>(fl::dtype::f64));
          }
      - name: '_dtypeBoolInt8'
        body: |
          static Napi::Value _dtypeBoolInt8(const Napi::CallbackInfo& info) {
            return Napi::Number::New(info.Env(), static_cast<double>(fl::dtype::b8));
          }
      - name: '_dtypeInt16'
        body: |
          static Napi::Value _dtypeInt16(const Napi::CallbackInfo& info) {
            return Napi::Number::New(info.Env(), static_cast<double>(fl::dtype::s16));
          }
      - name: '_dtypeInt32'
        body: |
          static Napi::Value _dtypeInt32(const Napi::CallbackInfo& info) {
            return Napi::Number::New(info.Env(), static_cast<double>(fl::dtype::s32));
          }
      - name: '_dtypeInt64'
        body: |
          static Napi::Value _dtypeInt64(const Napi::CallbackInfo& info) {
            return Napi::Number::New(info.Env(), static_cast<double>(fl::dtype::s64));
          }
      - name: '_dtypeUint8'
        body: |
          static Napi::Value _dtypeUint8(const Napi::CallbackInfo& info) {
            return Napi::Number::New(info.Env(), static_cast<double>(fl::dtype::u8));
          }
      - name: '_dtypeUint16'
        body: |
          static Napi::Value _dtypeUint16(const Napi::CallbackInfo& info) {
            return Napi::Number::New(info.Env(), static_cast<double>(fl::dtype::u16));
          }
      - name: '_dtypeUint32'
        body: |
          static Napi::Value _dtypeUint32(const Napi::CallbackInfo& info) {
            return Napi::Number::New(info.Env(), static_cast<double>(fl::dtype::u32));
          }
      - name: '_dtypeUint64'
        body: |
          static Napi::Value dtypeUint64(const Napi::CallbackInfo& info) {
            return Napi::Number::New(info.Env(), static_cast<double>(fl::dtype::u64));
          }
      - name: '_randn'
        body: |
          static Napi::Value randn(const Napi::CallbackInfo& info) {
            Napi::Env env = info.Env();
            if (info.Length() != 1 || !info[0].IsArray()) {
              Napi::TypeError::New(env, "`randn` expects exactly 1 arg; (expected type `number[]`)...").ThrowAsJavaScriptException();
              return env.Null();
            }
            std::vector<long long> shape =
                jsArrayArg<long long>(info[0].As<Napi::Array>(), g_row_major, false, env);
            fl::Tensor t;
            t = fl::randn(fl::Shape(shape));
            g_bytes_used += t.bytes();
            auto* tensor = new fl::Tensor(t);
            auto wrapped = Napi::External<fl::Tensor>::New(env, tensor);
            Napi::Value wrappedTensor = Tensor::constructor->New({wrapped});
            return wrappedTensor;
          }
    type_handlers:
      dtype:
        out_type: 'Napi::Number'
        out_var: '_out'
        handler: |
          Napi::Number _out = Napi::Number::New(env, static_cast<int>(/val/));
      Shape:
        out_type: 'Napi::TypedArrayOf<int64_t>'
        out_var: '_out'
        handler: |
          const size_t length = static_cast<const size_t>(this->_tensor->ndim());
          Napi::TypedArrayOf<int64_t> _out =
              Napi::TypedArrayOf<int64_t>::New(env, length, napi_bigint64_array);
          const int out_len = static_cast<int>(length);
          for (auto i = 0; i < out_len; ++i) {
            const auto idx = g_row_major ? out_len - i - 1 : i;
            _out[i] = static_cast<long long>(/val/[idx]);
          }
    class_opts:
      Tensor:
        constructor: |
          Tensor::Tensor(const Napi::CallbackInfo& info) : ObjectWrap(info) {
            Napi::Env env = info.Env();

            // throw error if number of args passed to constructor is not 1
            if (info.Length() != 1) {
              Napi::TypeError::New(env,
                                  "Invalid arg count when constructing Tensor "
                                  "(constructor expects exactly 1 arg)...")
                  .ThrowAsJavaScriptException();
              return;
            }

            if (info[0].IsExternal()) {
              auto tensor = info[0].As<Napi::External<fl::Tensor>>();
              this->_tensor = tensor.Data();
            }

            // TODO: handle `arg instanceof Tensor`
            if (info[0].IsObject()) {
              Napi::Object obj = info[0].As<Napi::Object>();
              if (obj.InstanceOf(Tensor::constructor->Value())) {
                Tensor* t = Napi::ObjectWrap<Tensor>::Unwrap(obj);
                this->_tensor = t->_tensor;

                // TODO: finish handling this case
                return;
              }
            }

            // TODO: handle `typeof arg === 'string
            if (info[0].IsString()) {
              Napi::String str = info[0].As<Napi::String>();
              std::string filename = str.Utf8Value();
              fl::Tensor* t = load(filename, env);
              this->_tensor = t;
              return;
            }

            // handle if arg is a TypedArray
            if (info[0].IsTypedArray()) {
              Napi::TypedArray underlying = info[0].As<Napi::TypedArray>();
              int64_t length = static_cast<int64_t>(underlying.ElementLength());
              napi_typedarray_type arrayType = underlying.TypedArrayType();
              switch (arrayType) {
                case napi_float32_array: {
                  Napi::TypedArrayOf<float> float_array =
                      underlying.As<Napi::TypedArrayOf<float>>();
                  float* ptr = float_array.Data();
                  auto* t = new fl::Tensor(
                      fl::Tensor::fromBuffer({length}, ptr, fl::MemoryLocation::Host));
                  g_bytes_used += t->bytes();
                  this->_tensor = t;
                  return;
                }
                case napi_float64_array: {
                  Napi::TypedArrayOf<double> double_array =
                      underlying.As<Napi::TypedArrayOf<double>>();
                  double* ptr = double_array.Data();
                  auto* t = new fl::Tensor(
                      fl::Tensor::fromBuffer({length}, ptr, fl::MemoryLocation::Host));
                  g_bytes_used += t->bytes();
                  this->_tensor = t;
                  return;
                }
                case napi_int8_array: {
                  Napi::TypedArrayOf<int8_t> int8_array =
                      underlying.As<Napi::TypedArrayOf<int8_t>>();
                  char* ptr = reinterpret_cast<char*>(int8_array.Data());
                  auto* t = new fl::Tensor(
                      fl::Tensor::fromBuffer({length}, ptr, fl::MemoryLocation::Host));
                  g_bytes_used += t->bytes();
                  this->_tensor = t;
                  return;
                }
                case napi_uint8_array: {
                  Napi::TypedArrayOf<uint8_t> uint8_array =
                      underlying.As<Napi::TypedArrayOf<uint8_t>>();
                  uint8_t* ptr = uint8_array.Data();
                  auto* t = new fl::Tensor(
                      fl::Tensor::fromBuffer({length}, ptr, fl::MemoryLocation::Host));
                  g_bytes_used += t->bytes();
                  this->_tensor = t;
                  return;
                }
                case napi_int16_array: {
                  Napi::TypedArrayOf<int16_t> int16_array =
                      underlying.As<Napi::TypedArrayOf<int16_t>>();
                  int16_t* ptr = int16_array.Data();
                  auto* t = new fl::Tensor(
                      fl::Tensor::fromBuffer({length}, ptr, fl::MemoryLocation::Host));
                  g_bytes_used += t->bytes();
                  this->_tensor = t;
                  return;
                }
                case napi_uint16_array: {
                  Napi::TypedArrayOf<uint16_t> uint16_array =
                      underlying.As<Napi::TypedArrayOf<uint16_t>>();
                  uint16_t* ptr = uint16_array.Data();
                  auto* t = new fl::Tensor(
                      fl::Tensor::fromBuffer({length}, ptr, fl::MemoryLocation::Host));
                  g_bytes_used += t->bytes();
                  this->_tensor = t;
                  return;
                }
                case napi_int32_array: {
                  Napi::TypedArrayOf<int32_t> int32_array =
                      underlying.As<Napi::TypedArrayOf<int32_t>>();
                  int32_t* ptr = int32_array.Data();
                  auto* t = new fl::Tensor(
                      fl::Tensor::fromBuffer({length}, ptr, fl::MemoryLocation::Host));
                  g_bytes_used += t->bytes();
                  this->_tensor = t;
                  return;
                }
                case napi_uint32_array: {
                  Napi::TypedArrayOf<uint32_t> uint32_array =
                      underlying.As<Napi::TypedArrayOf<uint32_t>>();
                  uint32_t* ptr = uint32_array.Data();
                  auto* t = new fl::Tensor(
                      fl::Tensor::fromBuffer({length}, ptr, fl::MemoryLocation::Host));
                  g_bytes_used += t->bytes();
                  this->_tensor = t;
                  return;
                }
                case napi_bigint64_array: {
                  Napi::TypedArrayOf<int64_t> bigint64_array =
                      underlying.As<Napi::TypedArrayOf<int64_t>>();
                  int64_t* ptr = bigint64_array.Data();
                  auto* t = new fl::Tensor(
                      fl::Tensor::fromBuffer({length}, ptr, fl::MemoryLocation::Host));
                  g_bytes_used += t->bytes();
                  this->_tensor = t;
                  return;
                }
                case napi_biguint64_array: {
                  Napi::TypedArrayOf<uint64_t> biguint64_array =
                      underlying.As<Napi::TypedArrayOf<uint64_t>>();
                  uint64_t* ptr = biguint64_array.Data();
                  auto* t = new fl::Tensor(
                      fl::Tensor::fromBuffer({length}, ptr, fl::MemoryLocation::Host));
                  g_bytes_used += t->bytes();
                  this->_tensor = t;
                  return;
                }
                default: {
                  Napi::TypeError::New(env, "Unhandled TypedArray type")
                      .ThrowAsJavaScriptException();
                  return;
                }
              }
            }

            // TODO: handle `typeof arg === 'number'`
            if (info[0].IsNumber()) {
              const size_t length = 1;
              Napi::TypedArrayOf<int64_t> arr =
                  Napi::TypedArrayOf<int64_t>::New(env, length, napi_bigint64_array);
              arr[0] = info[0].As<Napi::Number>().Int64Value();
              auto* ptr = arr.Data();
              auto shape = arrayArg<long long>(ptr, 1, g_row_major, false);
              auto* t = new fl::Tensor(fl::Shape(shape));
              g_bytes_used += t->bytes();
              this->_tensor = t;
              return;
            }
          }
        fields:
          - 'copy'
          - 'shape'
          - 'elements'
          - 'ndim'
          - 'isEmpty'
          - 'bytes'
          - 'strides'
          - 'astype'
          - 'type'
          - 'isSparse'
          - 'flatten'
          - 'asContiguousTensor'
          - 'isContiguous'
        methods:
          - 'reshape'
          - 'transpose'
          - 'tile'
          - 'nonzero'
          - 'negative'
          - 'logicalNot'
          - 'exp'
          - 'log'
          - 'log1p'
          - 'sin'
          - 'cos'
          - 'sqrt'
          - 'tanh'
          - 'floor'
          - 'ceil'
          - 'rint'
          - 'absolute'
          - 'sigmoid'
          - 'erf'
          - 'flip'
          - 'clip'
          - 'roll'
          - 'isnan'
          - 'isinf'
          - 'sign'
          - 'tril'
          - 'triu'
          - 'where'
          - 'sort'
          - 'add'
          - 'sub'
          - 'mul'
          - 'div'
          - 'eq'
          - 'neq'
          - 'lessThan'
          - 'lessThanEqual'
          - 'greaterThan'
          - 'greaterThanEqual'
          - 'logicalOr'
          - 'logicalAnd'
          - 'mod'
          - 'bitwiseAnd'
          - 'bitwiseOr'
          - 'bitwiseXor'
          - 'lShift'
          - 'rShift'
          - 'minimium'
          - 'maximum'
          - 'power'
          - 'matmul'
          - 'conv2d'
          - 'amin'
          - 'amax'
          - 'argmin'
          - 'sum'
          - 'cumsum'
          - 'mean'
          - 'median'
          - 'var'
          - 'std'
          - 'norm'
          - 'countNonzero'
          - 'any'
          - 'all'
        forced_methods:
          - name: 'toFloat32Array'
            body: |
              Napi::Value Tensor::toFloat32Array(const Napi::CallbackInfo& info) {
                Napi::Env env = info.Env();
                size_t elemLen = static_cast<size_t>(this->_tensor->elements());
                size_t byteLen = elemLen * sizeof(float);
                void* ptr = this->_tensor->astype(fl::dtype::f32).host<float>();
                Napi::ArrayBuffer buff = Napi::ArrayBuffer::New(env, ptr, byteLen);
                Napi::TypedArrayOf<float> out = Napi::TypedArrayOf<float>::New(env, elemLen, buff, 0, napi_float32_array);
                return out;
              }
          - name: 'toFloat64Array'
            body: |
              Napi::Value Tensor::toFloat64Array(const Napi::CallbackInfo& info) {
                Napi::Env env = info.Env();
                size_t elemLen = static_cast<size_t>(this->_tensor->elements());
                size_t byteLen = elemLen * sizeof(double);
                void* ptr = this->_tensor->astype(fl::dtype::f64).host<double>();
                Napi::ArrayBuffer buff = Napi::ArrayBuffer::New(env, ptr, byteLen);
                Napi::TypedArrayOf<double> out = Napi::TypedArrayOf<double>::New(env, elemLen, buff, 0, napi_float64_array);
                return out;
              }
          - name: 'toBoolInt8Array'
            body: |
              Napi::Value Tensor::toBoolInt8Array(const Napi::CallbackInfo& info) {
                Napi::Env env = info.Env();
                size_t elemLen = static_cast<size_t>(this->_tensor->elements());
                size_t byteLen = elemLen * sizeof(int8_t);
                void* ptr = this->_tensor->astype(fl::dtype::b8).host<int>();
                Napi::ArrayBuffer buff = Napi::ArrayBuffer::New(env, ptr, byteLen);
                Napi::TypedArrayOf<int8_t> out = Napi::TypedArrayOf<int8_t>::New(env, elemLen, buff, 0, napi_int8_array);
                return out;
              }
          - name: 'toInt16Array'
            body: |
              Napi::Value Tensor::toInt16Array(const Napi::CallbackInfo& info) {
                Napi::Env env = info.Env();
                size_t elemLen = static_cast<size_t>(this->_tensor->elements());
                size_t byteLen = elemLen * sizeof(int16_t);
                void* ptr = this->_tensor->astype(fl::dtype::s16).host<int>();
                Napi::ArrayBuffer buff = Napi::ArrayBuffer::New(env, ptr, byteLen);
                Napi::TypedArrayOf<int16_t> out = Napi::TypedArrayOf<int16_t>::New(env, elemLen, buff, 0, napi_int16_array);
                return out;
              }
          - name: 'toInt32Array'
            body: |
              Napi::Value Tensor::toInt32Array(const Napi::CallbackInfo& info) {
                Napi::Env env = info.Env();
                size_t elemLen = static_cast<size_t>(this->_tensor->elements());
                size_t byteLen = elemLen * sizeof(int32_t);
                void* ptr = this->_tensor->astype(fl::dtype::s32).host<int>();
                Napi::ArrayBuffer buff = Napi::ArrayBuffer::New(env, ptr, byteLen);
                Napi::TypedArrayOf<int32_t> out = Napi::TypedArrayOf<int32_t>::New(env, elemLen, buff, 0, napi_int32_array);
                return out;
              }
          - name: 'toInt64Array'
            body: |
              Napi::Value Tensor::toInt64Array(const Napi::CallbackInfo& info) {
                Napi::Env env = info.Env();
                size_t elemLen = static_cast<size_t>(this->_tensor->elements());
                size_t byteLen = elemLen * sizeof(int64_t);
                void* ptr = this->_tensor->astype(fl::dtype::s64).host<int>();
                Napi::ArrayBuffer buff = Napi::ArrayBuffer::New(env, ptr, byteLen);
                Napi::TypedArrayOf<int64_t> out = Napi::TypedArrayOf<int64_t>::New(env, elemLen, buff, 0, napi_bigint64_array);
                return out;
              }
          - name: 'toUint8Array'
            body: |
              Napi::Value Tensor::toUint8Array(const Napi::CallbackInfo& info) {
                Napi::Env env = info.Env();
                size_t elemLen = static_cast<size_t>(this->_tensor->elements());
                size_t byteLen = elemLen * sizeof(uint8_t);
                void* ptr = this->_tensor->astype(fl::dtype::u8).host<unsigned>();
                Napi::ArrayBuffer buff = Napi::ArrayBuffer::New(env, ptr, byteLen);
                Napi::TypedArrayOf<uint8_t> out = Napi::TypedArrayOf<uint8_t>::New(env, elemLen, buff, 0, napi_uint8_array);
                return out;
              }
          - name: 'toUint16Array'
            body: |
              Napi::Value Tensor::toUint16Array(const Napi::CallbackInfo& info) {
                Napi::Env env = info.Env();
                size_t elemLen = static_cast<size_t>(this->_tensor->elements());
                size_t byteLen = elemLen * sizeof(uint16_t);
                void* ptr = this->_tensor->astype(fl::dtype::u16).host<unsigned>();
                Napi::ArrayBuffer buff = Napi::ArrayBuffer::New(env, ptr, byteLen);
                Napi::TypedArrayOf<uint16_t> out = Napi::TypedArrayOf<uint16_t>::New(env, elemLen, buff, 0, napi_uint16_array);
                return out;
              }
          - name: 'toUint32Array'
            body: |
              Napi::Value Tensor::toUint32Array(const Napi::CallbackInfo& info) {
                Napi::Env env = info.Env();
                size_t elemLen = static_cast<size_t>(this->_tensor->elements());
                size_t byteLen = elemLen * sizeof(uint32_t);
                void* ptr = this->_tensor->astype(fl::dtype::u32).host<unsigned>();
                Napi::ArrayBuffer buff = Napi::ArrayBuffer::New(env, ptr, byteLen);
                Napi::TypedArrayOf<uint32_t> out = Napi::TypedArrayOf<uint32_t>::New(env, elemLen, buff, 0, napi_uint32_array);
                return out;
              }
          - name: 'toUint64Array'
            body: |
              Napi::Value Tensor::toUint64Array(const Napi::CallbackInfo& info) {
                Napi::Env env = info.Env();
                size_t elemLen = static_cast<size_t>(this->_tensor->elements());
                size_t byteLen = elemLen * sizeof(uint64_t);
                void* ptr = this->_tensor->astype(fl::dtype::u64).host<unsigned>();
                Napi::ArrayBuffer buff = Napi::ArrayBuffer::New(env, ptr, byteLen);
                Napi::TypedArrayOf<uint64_t> out = Napi::TypedArrayOf<uint64_t>::New(env, elemLen, buff, 0, napi_biguint64_array);
                return out;
              }
          - name: 'toFloat32Scalar'
            body: |
              Napi::Value Tensor::toFloat32Scalar(const Napi::CallbackInfo& info) {
                return Napi::Number::New(info.Env(), this->_tensor->asScalar<float>());
              }
          - name: 'toFloat64Scalar'
            body: |
              Napi::Value Tensor::toFloat64Scalar(const Napi::CallbackInfo& info) {
                return Napi::Number::New(info.Env(), this->_tensor->asScalar<double>());
              }
          - name: 'toBoolInt8Scalar'
            body: |
              Napi::Value Tensor::toBoolInt8Scalar(const Napi::CallbackInfo& info) {
                return Napi::Number::New(info.Env(), this->_tensor->asScalar<char>());
              }
          - name: 'toInt16Scalar'
            body: |
              Napi::Value Tensor::toInt16Scalar(const Napi::CallbackInfo& info) {
                return Napi::Number::New(info.Env(), this->_tensor->asScalar<int16_t>());
              }
          - name: 'toInt32Scalar'
            body: |
              Napi::Value Tensor::toInt32Scalar(const Napi::CallbackInfo& info) {
                return Napi::Number::New(info.Env(), this->_tensor->asScalar<int32_t>());
              }
          - name: 'toInt64Scalar'
            body: |
              Napi::Value Tensor::toInt64Scalar(const Napi::CallbackInfo& info) {
                return Napi::Number::New(info.Env(), this->_tensor->asScalar<int64_t>());
              }
          - name: 'toUint8Scalar'
            body: |
              Napi::Value Tensor::toUint8Scalar(const Napi::CallbackInfo& info) {
                return Napi::Number::New(info.Env(), this->_tensor->asScalar<uint8_t>());
              }
          - name: 'toUint16Scalar'
            body: |
              Napi::Value Tensor::toUint16Scalar(const Napi::CallbackInfo& info) {
                return Napi::Number::New(info.Env(), this->_tensor->asScalar<uint16_t>());
              }
          - name: 'toUint32Scalar'
            body: |
              Napi::Value Tensor::toUint32Scalar(const Napi::CallbackInfo& info) {
                return Napi::Number::New(info.Env(), this->_tensor->asScalar<uint32_t>());
              }
          - name: 'toUint64Scalar'
            body: |
              Napi::Value Tensor::toUint64Scalar(const Napi::CallbackInfo& info) {
                return Napi::Number::New(info.Env(), this->_tensor->asScalar<uint64_t>());
              }
          - name: 'eval'
            is_void: true
            body: |
              void Tensor::eval(const Napi::CallbackInfo& info) {
                fl::eval(*(this->_tensor));
              }
          - name: 'dispose'
            is_void: true
            body: |
              void Tensor::dispose(const Napi::CallbackInfo& info) {
                auto& tensor = *reinterpret_cast<fl::Tensor*>(this->_tensor);
                g_bytes_used -= tensor.bytes();
                fl::detail::releaseAdapterUnsafe(tensor);
              }
